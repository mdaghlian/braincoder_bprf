{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a73c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 15:35:39.563988: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-27 15:35:39.564068: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-27 15:35:39.564079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-27 15:35:39.573087: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Sanity check on implementation of \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import time\n",
    "# Set a limit on the memory usage of the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43c99af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cholesky' from 'scipy.sparse.linalg' (/home/daghlian/.conda/envs/bcoder005/lib/python3.11/site-packages/scipy/sparse/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cholesky\n\u001b[1;32m      6\u001b[0m cov_dense \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Assume you have a dense covariance matrix 'cov_dense' (tf.Tensor)\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cholesky' from 'scipy.sparse.linalg' (/home/daghlian/.conda/envs/bcoder005/lib/python3.11/site-packages/scipy/sparse/linalg/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import cholesky\n",
    "\n",
    "cov_dense = tf.random\n",
    "# Assume you have a dense covariance matrix 'cov_dense' (tf.Tensor)\n",
    "n = cov_dense.shape[0]\n",
    "\n",
    "# Try to convert to a sparse representation (example with thresholding)\n",
    "threshold = 1e-6\n",
    "sparse_indices = tf.where(tf.abs(cov_dense) > threshold)\n",
    "sparse_values = tf.gather_nd(cov_dense, sparse_indices)\n",
    "sparse_shape = cov_dense.shape\n",
    "cov_sparse_tf = tf.sparse.SparseTensor(sparse_indices, sparse_values, sparse_shape)\n",
    "\n",
    "# Convert to SciPy sparse matrix for operations not directly in TensorFlow\n",
    "cov_sparse_np = csr_matrix(cov_sparse_tf.numpy())\n",
    "\n",
    "# Attempt sparse Cholesky (using SciPy) - needs to be wrapped in tf.py_function for TensorFlow integration\n",
    "def sparse_cholesky_np(sparse_matrix):\n",
    "    try:\n",
    "        return cholesky(sparse_matrix, lower=True).toarray()\n",
    "    except Exception as e:\n",
    "        print(f\"Sparse Cholesky failed: {e}\")\n",
    "        return np.full_like(sparse_matrix.toarray(), np.nan) # Handle potential errors\n",
    "\n",
    "sparse_cholesky_tf = tf.py_function(\n",
    "    func=sparse_cholesky_np,\n",
    "    inp=[cov_sparse_np],\n",
    "    Tout=tf.float32\n",
    ")\n",
    "\n",
    "# ... (rest of your log probability calculation using the sparse Cholesky factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8037956",
   "metadata": {},
   "source": [
    "# Ensure that log prob calculations are the same as tfp implementation & faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your array (as a TensorFlow tensor)\n",
    "n_rows = 10000 # i.e., number of voxels \n",
    "n_cols = 200 # i.e., number of samples in timeseries\n",
    "num_iterations = 1000\n",
    "data = tf.constant(np.random.rand(n_rows, n_cols), dtype=tf.float32)\n",
    "scale_values = tf.constant(np.random.rand(n_rows, 1), dtype=tf.float32)\n",
    "dof_values = tf.constant(np.random.rand(n_rows, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2112a",
   "metadata": {},
   "source": [
    "#### testing calculate_log_prob_gauss_loc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0464cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from braincoder.utils.math import calculate_log_prob_gauss_loc0\n",
    "# for device in ['GPU', 'CPU']:\n",
    "#     print(f'Trying with {device}')\n",
    "#     with tf.device(f'/{device}:0'):\n",
    "#         # Timing the custom log probability calculation\n",
    "#         calculate_log_prob_gauss_loc0(data, scale_values) # Compile / warm up first\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             calculate_log_prob_gauss_loc0(data, scale_values)  # Now correctly broadcasted\n",
    "#         time_custom = time.time() - start_time\n",
    "#         output_custom = calculate_log_prob_gauss_loc0(data, scale_values)\n",
    "#         # Timing the TFP log probability calculation\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             normal_dist = tfp.distributions.Normal(loc=0.0, scale=scale_values)  # Correct shape\n",
    "#             normal_dist.log_prob(data)  # Correct shape\n",
    "#         time_tfd = time.time() - start_time\n",
    "#         output_tfd = normal_dist.log_prob(data)\n",
    "#         # Print the results\n",
    "#         print(f\"Custom log probability calculation time over {num_iterations} iterations: {time_custom:.6f} seconds\")\n",
    "#         print(f\"TFP log probability calculation time over {num_iterations} iterations: {time_tfd:.6f} seconds\")\n",
    "#         print(f\"Custom method is  {time_tfd/time_custom:.3f} x faster\")\n",
    "#         print(f\"     tfd,        custom\")\n",
    "#         for i1 in range(3):\n",
    "#             for i2 in range(3):\n",
    "#                 print(f'{output_tfd[i1,i2]:10.3f}, {output_custom[i1,i2]:10.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ae006",
   "metadata": {},
   "source": [
    "#### Testing calculate_log_prob_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from braincoder.utils.math import calculate_log_prob_t\n",
    "# for device in ['GPU', 'CPU']:\n",
    "#     print(f'Trying with {device}')\n",
    "#     with tf.device(f'/{device}:0'):\n",
    "#         # Timing the custom log probability calculation\n",
    "#         calculate_log_prob_t(data, scale_values, dof_values) # warm up first\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             calculate_log_prob_t(data, scale_values, dof_values)  # Now correctly broadcasted\n",
    "#         time_custom = time.time() - start_time\n",
    "#         output_custom = calculate_log_prob_t(data, scale_values, dof_values)\n",
    "\n",
    "#         # Timing the TFP log probability calculation\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             t_dist = tfp.distributions.StudentT(df=dof_values, loc=0.0, scale=scale_values)  # Correct shape\n",
    "#             t_dist.log_prob(data)  # Correct shape\n",
    "#         time_tfd = time.time() - start_time\n",
    "#         output_tfd = t_dist.log_prob(data)\n",
    "\n",
    "#         # Print the results\n",
    "#         print(f\"Custom log probability calculation time over {num_iterations} iterations: {time_custom:.6f} seconds\")\n",
    "#         print(f\"TFP log probability calculation time over {num_iterations} iterations: {time_tfd:.6f} seconds\")\n",
    "#         print(f\"Custom method is  {time_tfd/time_custom:.3f} x faster\")\n",
    "#         print(f\"     tfd,        custom\")\n",
    "#         for i1 in range(3):\n",
    "#             for i2 in range(3):\n",
    "#                 print(f'{output_tfd[i1,i2]:10.3f}, {output_custom[i1,i2]:10.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c1f71",
   "metadata": {},
   "source": [
    "# Check GP dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "# import math\n",
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "# tfd = tfp.distributions\n",
    "\n",
    "# for device in ['GPU', 'CPU']:\n",
    "#     print(f'\\n\\n\\n\\n\\nTrying with {device}')\n",
    "#     with tf.device(f'/{device}:0'):\n",
    "#         # Create a dummy symmetric distance matrix.\n",
    "#         n_vx = 500\n",
    "#         rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "#         dists = (rand + tf.transpose(rand)) / 2.0\n",
    "#         dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "#         # Set hyperparameters.\n",
    "#         gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "#         gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "#         gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "#         gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "#         # Instantiate GPdists with fixed hyperparameters.\n",
    "#         gp_fixed = GPdists(\n",
    "#             dists,\n",
    "#             fixed_params='fixed_all',\n",
    "#             full_norm=False, \n",
    "#             gp_variance=gp_variance,\n",
    "#             gp_lengthscale=gp_lengthscale,\n",
    "#             gp_mean=gp_mean,\n",
    "#             gp_nugget=gp_nugget,\n",
    "#             psd_control='euclidean',\n",
    "#             dists_dtype=tf.float64, # for cholesky... \n",
    "#             kernel='RBF',\n",
    "#         )\n",
    "\n",
    "#         # For comparison, get the covariance matrix computed by GPdists.\n",
    "#         cov_matrix = gp_fixed.cov_matrix\n",
    "\n",
    "#         # Create a random parameter vector (matching the number of vertices).\n",
    "#         parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "#         # Warm-up (to compile tf.function graphs)\n",
    "#         _ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "#         _ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "#         # Timing the fixed TF method.\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "#             _ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "#         time_fixed_tf = time.time() - start_time\n",
    "\n",
    "#         # Timing the fixed precision method.\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "#             _ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "#         time_fixed_prec = time.time() - start_time\n",
    "\n",
    "#         print(f\"Timing for Fixed TF method: {time_fixed_tf:.6f} seconds\")\n",
    "#         print(f\"Timing for Fixed Precision method: {time_fixed_prec:.6f} seconds\")\n",
    "#         print(f\"Fixed Precision is  {time_fixed_tf/time_fixed_prec:.3f} x faster\")\n",
    "#         # Compute log probability using the fixed TF method.\n",
    "#         log_prob_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "#         # Compute log probability using the fixed precision method.\n",
    "#         log_prob_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "#         print(\"Log probability (Fixed TF):       \", log_prob_fixed_tf.numpy())\n",
    "#         print(\"Log probability (Fixed Precision):  \", log_prob_fixed_prec.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d519cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "\n",
    "for device in ['GPU', 'CPU']:\n",
    "    print(f'\\n\\n\\n\\n\\nTrying with {device}')\n",
    "    with tf.device(f'/{device}:0'):\n",
    "        # Create a dummy symmetric distance matrix.\n",
    "        n_vx = 500\n",
    "        rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "        dists = (rand + tf.transpose(rand)) / 2.0\n",
    "        dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "        # Set hyperparameters.\n",
    "        gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "        gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "        gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "        gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "        # Instantiate GPdists with fixed hyperparameters.\n",
    "        gp_fixed = GPdists(\n",
    "            dists,\n",
    "            fixed_params='unfixed',\n",
    "            full_norm=False, \n",
    "            gp_variance=gp_variance,\n",
    "            gp_lengthscale=gp_lengthscale,\n",
    "            gp_mean=gp_mean,\n",
    "            gp_nugget=gp_nugget,\n",
    "            psd_control='euclidean',\n",
    "            dists_dtype=tf.float64, # for cholesky... \n",
    "            kernel='RBF',\n",
    "        )\n",
    "\n",
    "        # For comparison, get the covariance matrix computed by GPdists.\n",
    "        cov_matrix = gp_fixed.cov_matrix\n",
    "\n",
    "        # Create a random parameter vector (matching the number of vertices).\n",
    "        parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "        # Warm-up (to compile tf.function graphs)\n",
    "        _ = gp_fixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        _ = gp_fixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        # Timing the fixed TF method.\n",
    "        start_time = time.time()\n",
    "        for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "            _ = gp_fixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        time_fixed_tf = time.time() - start_time\n",
    "\n",
    "        # Timing the fixed precision method.\n",
    "        start_time = time.time()\n",
    "        for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "            _ = gp_fixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        time_fixed_prec = time.time() - start_time\n",
    "\n",
    "        print(f\"Timing for Unfixed TF method: {time_fixed_tf:.6f} seconds\")\n",
    "        print(f\"Timing for Unfixed Precision method: {time_fixed_prec:.6f} seconds\")\n",
    "        print(f\"Unfixed Precision is  {time_fixed_tf/time_fixed_prec:.3f} x faster\")\n",
    "        # Compute log probability using the fixed TF method.\n",
    "        log_prob_fixed_tf = gp_fixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        # Compute log probability using the fixed precision method.\n",
    "        log_prob_fixed_prec = gp_fixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        print(\"Log probability (Unfixed TF):       \", log_prob_fixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Precision):  \", log_prob_fixed_prec.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ca8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "full_norm = True\n",
    "# ------------------------------\n",
    "# Setup: create a dummy distance matrix.\n",
    "# ------------------------------\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "# Note: GPdists expects the distance tensor to be tf.float64 (for Cholesky) so we set that,\n",
    "# but the parameter vector itself is in tf.float32.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# Instantiate GPdists: fixed and unfixed versions.\n",
    "# ------------------------------\n",
    "# Fixed instance: precomputes covariance matrix, Cholesky, and precision.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=full_norm,  # Option for full normalization in precision-based log_prob.\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,  # ensure Cholesky and covariance are computed in float64\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',  # choose 'precision' for testing the new option.\n",
    ")\n",
    "\n",
    "# Unfixed instance: recomputes covariance every time.\n",
    "gp_unfixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=False,\n",
    "    full_norm=full_norm,  # will be passed to unfixed precision method\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create a random parameter vector (matches number of vertices).\n",
    "# ------------------------------\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper function to time method calls.\n",
    "# ------------------------------\n",
    "def time_method(method, instance, param, iterations=5000, **kwargs):\n",
    "    # Warm-up one call outside timing\n",
    "    _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    start = time.time()\n",
    "    for _ in range(iterations):\n",
    "        _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    return (time.time() - start) / iterations\n",
    "\n",
    "# ------------------------------\n",
    "# Devices to test (CPU and GPU if available)\n",
    "# ------------------------------\n",
    "devices = ['/cpu:0']\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    devices.append('/gpu:0')\n",
    "\n",
    "# ------------------------------\n",
    "# Run tests on each device.\n",
    "# ------------------------------\n",
    "for device in devices:\n",
    "    print(\"\\nTesting on device:\", device)\n",
    "    with tf.device(device):\n",
    "        # Fixed methods.\n",
    "        t_fixed_tf = time_method(gp_fixed._return_log_prob_fixed_tf, gp_fixed, parameter)\n",
    "        t_fixed_prec = time_method(gp_fixed._return_log_prob_fixed_prec, gp_fixed, parameter)\n",
    "        \n",
    "        # Unfixed methods.\n",
    "        t_unfixed_tf = time_method(gp_unfixed._return_log_prob_unfixed_tf, gp_unfixed, parameter)\n",
    "        t_unfixed_prec = time_method(gp_unfixed._return_log_prob_unfixed_prec, gp_unfixed, parameter)\n",
    "        \n",
    "        # Compute log probabilities (for a single call).\n",
    "        lp_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_tf = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_prec = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        \n",
    "        print(\"Log probability (Fixed TF):        \", lp_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Prec):        \", lp_fixed_prec.numpy())\n",
    "        print(\"Log probability (Unfixed TF):        \", lp_unfixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Prec):      \", lp_unfixed_prec.numpy())\n",
    "        \n",
    "        print(\"\\nAverage runtime per call:\")\n",
    "        print(\"  Fixed TF method:      {:.6f} sec\".format(t_fixed_tf))\n",
    "        print(\"  Fixed Precision method: {:.6f} sec\".format(t_fixed_prec))\n",
    "        print(\"  Unfixed TF method:    {:.6f} sec\".format(t_unfixed_tf))\n",
    "        print(\"  Unfixed Precision method: {:.6f} sec\".format(t_unfixed_prec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "full_norm = False\n",
    "# ------------------------------\n",
    "# Setup: create a dummy distance matrix.\n",
    "# ------------------------------\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "# Note: GPdists expects the distance tensor to be tf.float64 (for Cholesky) so we set that,\n",
    "# but the parameter vector itself is in tf.float32.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# Instantiate GPdists: fixed and unfixed versions.\n",
    "# ------------------------------\n",
    "# Fixed instance: precomputes covariance matrix, Cholesky, and precision.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=True,  # Option for full normalization in precision-based log_prob.\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,  # ensure Cholesky and covariance are computed in float64\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',  # choose 'precision' for testing the new option.\n",
    ")\n",
    "\n",
    "# Unfixed instance: recomputes covariance every time.\n",
    "gp_unfixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=False,\n",
    "    full_norm=True,  # will be passed to unfixed precision method\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create a random parameter vector (matches number of vertices).\n",
    "# ------------------------------\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper function to time method calls.\n",
    "# ------------------------------\n",
    "def time_method(method, instance, param, iterations=100, **kwargs):\n",
    "    # Warm-up one call outside timing\n",
    "    _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    start = time.time()\n",
    "    for _ in range(iterations):\n",
    "        _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    return (time.time() - start) / iterations\n",
    "\n",
    "# ------------------------------\n",
    "# Devices to test (CPU and GPU if available)\n",
    "# ------------------------------\n",
    "devices = ['/cpu:0']\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    devices.append('/gpu:0')\n",
    "\n",
    "# ------------------------------\n",
    "# Run tests on each device.\n",
    "# ------------------------------\n",
    "for device in devices:\n",
    "    print(\"\\nTesting on device:\", device)\n",
    "    with tf.device(device):\n",
    "        # Fixed methods.\n",
    "        t_fixed_tf = time_method(gp_fixed._return_log_prob_fixed_tf, gp_fixed, parameter)\n",
    "        t_fixed_prec = time_method(gp_fixed._return_log_prob_fixed_prec, gp_fixed, parameter, full_norm=True)\n",
    "        \n",
    "        # Unfixed methods.\n",
    "        t_unfixed_tf = time_method(gp_unfixed._return_log_prob_unfixed_tf, gp_unfixed, parameter)\n",
    "        t_unfixed_prec = time_method(gp_unfixed._return_log_prob_unfixed_prec, gp_unfixed, parameter, full_norm=True)\n",
    "        \n",
    "        # Compute log probabilities (for a single call).\n",
    "        lp_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "        lp_unfixed_tf = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_prec = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "        \n",
    "        print(\"Log probability (Fixed TF):        \", lp_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Prec):        \", lp_fixed_prec.numpy())\n",
    "        print(\"Log probability (Unfixed TF):        \", lp_unfixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Prec):      \", lp_unfixed_prec.numpy())\n",
    "        \n",
    "        print(\"\\nAverage runtime per call:\")\n",
    "        print(\"  Fixed TF method:      {:.6f} sec\".format(t_fixed_tf))\n",
    "        print(\"  Fixed Precision method: {:.6f} sec\".format(t_fixed_prec))\n",
    "        print(\"  Unfixed TF method:    {:.6f} sec\".format(t_unfixed_tf))\n",
    "        print(\"  Unfixed Precision method: {:.6f} sec\".format(t_unfixed_prec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0416b44",
   "metadata": {},
   "source": [
    "# bloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ebd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Generate a random positive definite covariance matrix for a 5-dimensional Gaussian.\n",
    "n = 5\n",
    "# Create a random matrix and form a covariance matrix by A * A^T.\n",
    "A = tf.random.normal((n, n), dtype=tf.float64)\n",
    "cov = tf.matmul(A, A, transpose_b=True) + tf.eye(n, dtype=tf.float64)*1e-3\n",
    "mean = tf.random.normal((n,), dtype=tf.float64)\n",
    "x = tf.random.normal((n,), dtype=tf.float64)\n",
    "\n",
    "# 1. Log probability using TFP's MultivariateNormalFullCovariance:\n",
    "dist = tfd.MultivariateNormalFullCovariance(loc=mean, covariance_matrix=cov)\n",
    "log_prob_tfp = dist.log_prob(x)\n",
    "\n",
    "# 2. Log probability using the full Gaussian formula:\n",
    "#    log p(x) = -0.5 * [ n*log(2π) + log|cov| + (x-mean)^T cov^-1 (x-mean) ]\n",
    "def full_gaussian_log_prob(x, mean, cov):\n",
    "    n = tf.cast(tf.shape(x)[0], cov.dtype)\n",
    "    diff = x - mean\n",
    "    inv_cov = tf.linalg.inv(cov)\n",
    "    log_det_cov = tf.linalg.logdet(cov)\n",
    "    quad_form = tf.tensordot(diff, tf.linalg.matvec(inv_cov, diff), axes=1)\n",
    "    # Cast constant 2*pi to the same dtype as cov\n",
    "    two_pi = tf.constant(2 * math.pi, dtype=cov.dtype)\n",
    "    return -0.5 * (n * tf.math.log(two_pi) + log_det_cov + quad_form)\n",
    "\n",
    "log_prob_full = full_gaussian_log_prob(x, mean, cov)\n",
    "\n",
    "# 3. Log probability using the precision matrix directly:\n",
    "#    We use the fact that:\n",
    "#      log p(x) = 0.5 * log|Q| - 0.5 * (x-mean)^T Q (x-mean) - (n/2)*log(2π)\n",
    "#    where Q = cov^-1.\n",
    "Q = tf.linalg.inv(cov)\n",
    "log_det_Q = tf.linalg.logdet(Q)\n",
    "diff = x - mean\n",
    "quad_form_precision = tf.tensordot(diff, tf.linalg.matvec(Q, diff), axes=1)\n",
    "two_pi = tf.constant(2 * math.pi, dtype=cov.dtype)\n",
    "log_prob_precision = 0.5 * log_det_Q - 0.5 * quad_form_precision - 0.5 * tf.cast(n, cov.dtype) * tf.math.log(two_pi)\n",
    "\n",
    "print(\"Log probability (TFP):         \", log_prob_tfp.numpy())\n",
    "print(\"Log probability (Full formula):\", log_prob_full.numpy())\n",
    "print(\"Log probability (Precision):   \", log_prob_precision.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcoder005",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

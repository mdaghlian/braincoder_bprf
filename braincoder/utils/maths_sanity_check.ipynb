{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a73c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 10:13:06.151650: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-08 10:13:06.151693: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-08 10:13:06.151721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-08 10:13:06.160623: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Sanity check on implementation of \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import time\n",
    "# Set a limit on the memory usage of the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import cholesky\n",
    "\n",
    "cov_dense = tf.random\n",
    "# Assume you have a dense covariance matrix 'cov_dense' (tf.Tensor)\n",
    "n = cov_dense.shape[0]\n",
    "\n",
    "# Try to convert to a sparse representation (example with thresholding)\n",
    "threshold = 1e-6\n",
    "sparse_indices = tf.where(tf.abs(cov_dense) > threshold)\n",
    "sparse_values = tf.gather_nd(cov_dense, sparse_indices)\n",
    "sparse_shape = cov_dense.shape\n",
    "cov_sparse_tf = tf.sparse.SparseTensor(sparse_indices, sparse_values, sparse_shape)\n",
    "\n",
    "# Convert to SciPy sparse matrix for operations not directly in TensorFlow\n",
    "cov_sparse_np = csr_matrix(cov_sparse_tf.numpy())\n",
    "\n",
    "# Attempt sparse Cholesky (using SciPy) - needs to be wrapped in tf.py_function for TensorFlow integration\n",
    "def sparse_cholesky_np(sparse_matrix):\n",
    "    try:\n",
    "        return cholesky(sparse_matrix, lower=True).toarray()\n",
    "    except Exception as e:\n",
    "        print(f\"Sparse Cholesky failed: {e}\")\n",
    "        return np.full_like(sparse_matrix.toarray(), np.nan) # Handle potential errors\n",
    "\n",
    "sparse_cholesky_tf = tf.py_function(\n",
    "    func=sparse_cholesky_np,\n",
    "    inp=[cov_sparse_np],\n",
    "    Tout=tf.float32\n",
    ")\n",
    "\n",
    "# ... (rest of your log probability calculation using the sparse Cholesky factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8037956",
   "metadata": {},
   "source": [
    "# Ensure that log prob calculations are the same as tfp implementation & faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your array (as a TensorFlow tensor)\n",
    "n_rows = 10000 # i.e., number of voxels \n",
    "n_cols = 200 # i.e., number of samples in timeseries\n",
    "num_iterations = 1000\n",
    "data = tf.constant(np.random.rand(n_rows, n_cols), dtype=tf.float32)\n",
    "scale_values = tf.constant(np.random.rand(n_rows, 1), dtype=tf.float32)\n",
    "dof_values = tf.constant(np.random.rand(n_rows, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2112a",
   "metadata": {},
   "source": [
    "#### testing calculate_log_prob_gauss_loc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0464cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from braincoder.utils.math import calculate_log_prob_gauss_loc0\n",
    "# for device in ['GPU', 'CPU']:\n",
    "#     print(f'Trying with {device}')\n",
    "#     with tf.device(f'/{device}:0'):\n",
    "#         # Timing the custom log probability calculation\n",
    "#         calculate_log_prob_gauss_loc0(data, scale_values) # Compile / warm up first\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             calculate_log_prob_gauss_loc0(data, scale_values)  # Now correctly broadcasted\n",
    "#         time_custom = time.time() - start_time\n",
    "#         output_custom = calculate_log_prob_gauss_loc0(data, scale_values)\n",
    "#         # Timing the TFP log probability calculation\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             normal_dist = tfp.distributions.Normal(loc=0.0, scale=scale_values)  # Correct shape\n",
    "#             normal_dist.log_prob(data)  # Correct shape\n",
    "#         time_tfd = time.time() - start_time\n",
    "#         output_tfd = normal_dist.log_prob(data)\n",
    "#         # Print the results\n",
    "#         print(f\"Custom log probability calculation time over {num_iterations} iterations: {time_custom:.6f} seconds\")\n",
    "#         print(f\"TFP log probability calculation time over {num_iterations} iterations: {time_tfd:.6f} seconds\")\n",
    "#         print(f\"Custom method is  {time_tfd/time_custom:.3f} x faster\")\n",
    "#         print(f\"     tfd,        custom\")\n",
    "#         for i1 in range(3):\n",
    "#             for i2 in range(3):\n",
    "#                 print(f'{output_tfd[i1,i2]:10.3f}, {output_custom[i1,i2]:10.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ae006",
   "metadata": {},
   "source": [
    "#### Testing calculate_log_prob_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from braincoder.utils.math import calculate_log_prob_t\n",
    "# for device in ['GPU', 'CPU']:\n",
    "#     print(f'Trying with {device}')\n",
    "#     with tf.device(f'/{device}:0'):\n",
    "#         # Timing the custom log probability calculation\n",
    "#         calculate_log_prob_t(data, scale_values, dof_values) # warm up first\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             calculate_log_prob_t(data, scale_values, dof_values)  # Now correctly broadcasted\n",
    "#         time_custom = time.time() - start_time\n",
    "#         output_custom = calculate_log_prob_t(data, scale_values, dof_values)\n",
    "\n",
    "#         # Timing the TFP log probability calculation\n",
    "#         start_time = time.time()\n",
    "#         for _ in range(num_iterations):\n",
    "#             t_dist = tfp.distributions.StudentT(df=dof_values, loc=0.0, scale=scale_values)  # Correct shape\n",
    "#             t_dist.log_prob(data)  # Correct shape\n",
    "#         time_tfd = time.time() - start_time\n",
    "#         output_tfd = t_dist.log_prob(data)\n",
    "\n",
    "#         # Print the results\n",
    "#         print(f\"Custom log probability calculation time over {num_iterations} iterations: {time_custom:.6f} seconds\")\n",
    "#         print(f\"TFP log probability calculation time over {num_iterations} iterations: {time_tfd:.6f} seconds\")\n",
    "#         print(f\"Custom method is  {time_tfd/time_custom:.3f} x faster\")\n",
    "#         print(f\"     tfd,        custom\")\n",
    "#         for i1 in range(3):\n",
    "#             for i2 in range(3):\n",
    "#                 print(f'{output_tfd[i1,i2]:10.3f}, {output_custom[i1,i2]:10.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c1f71",
   "metadata": {},
   "source": [
    "# Check GP dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21844a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trying with CPU\n",
      "Embedding in Euclidean space...\n",
      "Precomputing covariance matrix...\n",
      "Precomputing Cholesky decomposition...\n",
      "Timing for Fixed TF method: 1.186564 seconds\n",
      "Timing for Fixed Precision method: 6.234229 seconds\n",
      "Fixed Precision is  0.190 x faster\n",
      "Log probability (Fixed TF):        -2492.4941\n",
      "Log probability (Fixed Precision):   -2492.4941\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "# Force CPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "\n",
    "for device in ['CPU']: #, 'GPU']:\n",
    "    print(f'\\n\\n\\n\\n\\nTrying with {device}')\n",
    "    with tf.device(f'/{device}:0'):\n",
    "        # Create a dummy symmetric distance matrix.\n",
    "        n_vx = 500\n",
    "        rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "        dists = (rand + tf.transpose(rand)) / 2.0\n",
    "        dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "        # Set hyperparameters.\n",
    "        gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "        gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "        gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "        gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "        # Instantiate GPdists with fixed hyperparameters.\n",
    "        gp_fixed = GPdists(\n",
    "            dists,\n",
    "            fixed_params='fixed_all',\n",
    "            full_norm=True, \n",
    "            gp_variance=gp_variance,\n",
    "            gp_lengthscale=gp_lengthscale,\n",
    "            gp_mean=gp_mean,\n",
    "            gp_nugget=gp_nugget,\n",
    "            psd_control='euclidean',\n",
    "            dists_dtype=tf.float64, # for cholesky... \n",
    "            kernel='RBF',\n",
    "        )\n",
    "\n",
    "        # For comparison, get the covariance matrix computed by GPdists.\n",
    "        cov_matrix = gp_fixed.cov_matrix\n",
    "\n",
    "        # Create a random parameter vector (matching the number of vertices).\n",
    "        parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "        # Warm-up (to compile tf.function graphs)\n",
    "        _ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        _ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        # Timing the fixed TF method.\n",
    "        start_time = time.time()\n",
    "        for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "            _ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        time_fixed_tf = time.time() - start_time\n",
    "\n",
    "        # Timing the fixed precision method.\n",
    "        start_time = time.time()\n",
    "        for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "            _ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        time_fixed_prec = time.time() - start_time\n",
    "\n",
    "        print(f\"Timing for Fixed TF method: {time_fixed_tf:.6f} seconds\")\n",
    "        print(f\"Timing for Fixed Precision method: {time_fixed_prec:.6f} seconds\")\n",
    "        print(f\"Fixed Precision is  {time_fixed_tf/time_fixed_prec:.3f} x faster\")\n",
    "        # Compute log probability using the fixed TF method.\n",
    "        log_prob_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        # Compute log probability using the fixed precision method.\n",
    "        log_prob_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        print(\"Log probability (Fixed TF):       \", log_prob_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Precision):  \", log_prob_fixed_prec.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d519cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:56:22.433371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-28 14:56:22.433430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-28 14:56:22.433464: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-28 14:56:22.441904: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trying with GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:56:35.997609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10756 MB memory:  -> device: 0, name: Tesla K40m, pci bus id: 0000:03:00.0, compute capability: 3.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding in Euclidean space...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 14:56:37.497816: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x55e7a7f7d670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing for Unfixed TF method: 3.113849 seconds\n",
      "Timing for Unfixed Precision method: 10.321810 seconds\n",
      "Unfixed Precision is  0.302 x faster\n",
      "Log probability (Unfixed TF):        -2202.2886\n",
      "Log probability (Unfixed Precision):   -2250.0566\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trying with CPU\n",
      "Embedding in Euclidean space...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):  \u001b[38;5;66;03m# Adjust the number of iterations as needed.\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mgp_fixed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_log_prob_unfixed_prec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp_lengthscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp_variance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgp_nugget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m time_fixed_prec \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTiming for Unfixed TF method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_fixed_tf\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "\n",
    "for device in ['GPU', 'CPU']:\n",
    "    print(f'\\n\\n\\n\\n\\nTrying with {device}')\n",
    "    with tf.device(f'/{device}:0'):\n",
    "        # Create a dummy symmetric distance matrix.\n",
    "        n_vx = 500\n",
    "        rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "        dists = (rand + tf.transpose(rand)) / 2.0\n",
    "        dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "        # Set hyperparameters.\n",
    "        gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "        gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "        gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "        gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "        # Instantiate GPdists with fixed hyperparameters.\n",
    "        gp_fixed = GPdists(\n",
    "            dists,\n",
    "            fixed_params='unfixed',\n",
    "            full_norm=False, \n",
    "            gp_variance=gp_variance,\n",
    "            gp_lengthscale=gp_lengthscale,\n",
    "            gp_mean=gp_mean,\n",
    "            gp_nugget=gp_nugget,\n",
    "            psd_control='euclidean',\n",
    "            dists_dtype=tf.float64, # for cholesky... \n",
    "            kernel='RBF',\n",
    "        )\n",
    "\n",
    "        # For comparison, get the covariance matrix computed by GPdists.\n",
    "        cov_matrix = gp_fixed.cov_matrix\n",
    "\n",
    "        # Create a random parameter vector (matching the number of vertices).\n",
    "        parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "        # Warm-up (to compile tf.function graphs)\n",
    "        _ = gp_fixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        _ = gp_fixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        # Timing the fixed TF method.\n",
    "        start_time = time.time()\n",
    "        for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "            _ = gp_fixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        time_fixed_tf = time.time() - start_time\n",
    "\n",
    "        # Timing the fixed precision method.\n",
    "        start_time = time.time()\n",
    "        for _ in range(1000):  # Adjust the number of iterations as needed.\n",
    "            _ = gp_fixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        time_fixed_prec = time.time() - start_time\n",
    "\n",
    "        print(f\"Timing for Unfixed TF method: {time_fixed_tf:.6f} seconds\")\n",
    "        print(f\"Timing for Unfixed Precision method: {time_fixed_prec:.6f} seconds\")\n",
    "        print(f\"Unfixed Precision is  {time_fixed_tf/time_fixed_prec:.3f} x faster\")\n",
    "        # Compute log probability using the fixed TF method.\n",
    "        log_prob_fixed_tf = gp_fixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        # Compute log probability using the fixed precision method.\n",
    "        log_prob_fixed_prec = gp_fixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "        print(\"Log probability (Unfixed TF):       \", log_prob_fixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Precision):  \", log_prob_fixed_prec.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ca8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7710d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "full_norm = True\n",
    "# ------------------------------\n",
    "# Setup: create a dummy distance matrix.\n",
    "# ------------------------------\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "# Note: GPdists expects the distance tensor to be tf.float64 (for Cholesky) so we set that,\n",
    "# but the parameter vector itself is in tf.float32.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# Instantiate GPdists: fixed and unfixed versions.\n",
    "# ------------------------------\n",
    "# Fixed instance: precomputes covariance matrix, Cholesky, and precision.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=full_norm,  # Option for full normalization in precision-based log_prob.\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,  # ensure Cholesky and covariance are computed in float64\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',  # choose 'precision' for testing the new option.\n",
    ")\n",
    "\n",
    "# Unfixed instance: recomputes covariance every time.\n",
    "gp_unfixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=False,\n",
    "    full_norm=full_norm,  # will be passed to unfixed precision method\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create a random parameter vector (matches number of vertices).\n",
    "# ------------------------------\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper function to time method calls.\n",
    "# ------------------------------\n",
    "def time_method(method, instance, param, iterations=5000, **kwargs):\n",
    "    # Warm-up one call outside timing\n",
    "    _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    start = time.time()\n",
    "    for _ in range(iterations):\n",
    "        _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    return (time.time() - start) / iterations\n",
    "\n",
    "# ------------------------------\n",
    "# Devices to test (CPU and GPU if available)\n",
    "# ------------------------------\n",
    "devices = ['/cpu:0']\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    devices.append('/gpu:0')\n",
    "\n",
    "# ------------------------------\n",
    "# Run tests on each device.\n",
    "# ------------------------------\n",
    "for device in devices:\n",
    "    print(\"\\nTesting on device:\", device)\n",
    "    with tf.device(device):\n",
    "        # Fixed methods.\n",
    "        t_fixed_tf = time_method(gp_fixed._return_log_prob_fixed_tf, gp_fixed, parameter)\n",
    "        t_fixed_prec = time_method(gp_fixed._return_log_prob_fixed_prec, gp_fixed, parameter)\n",
    "        \n",
    "        # Unfixed methods.\n",
    "        t_unfixed_tf = time_method(gp_unfixed._return_log_prob_unfixed_tf, gp_unfixed, parameter)\n",
    "        t_unfixed_prec = time_method(gp_unfixed._return_log_prob_unfixed_prec, gp_unfixed, parameter)\n",
    "        \n",
    "        # Compute log probabilities (for a single call).\n",
    "        lp_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_tf = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_prec = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        \n",
    "        print(\"Log probability (Fixed TF):        \", lp_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Prec):        \", lp_fixed_prec.numpy())\n",
    "        print(\"Log probability (Unfixed TF):        \", lp_unfixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Prec):      \", lp_unfixed_prec.numpy())\n",
    "        \n",
    "        print(\"\\nAverage runtime per call:\")\n",
    "        print(\"  Fixed TF method:      {:.6f} sec\".format(t_fixed_tf))\n",
    "        print(\"  Fixed Precision method: {:.6f} sec\".format(t_fixed_prec))\n",
    "        print(\"  Unfixed TF method:    {:.6f} sec\".format(t_unfixed_tf))\n",
    "        print(\"  Unfixed Precision method: {:.6f} sec\".format(t_unfixed_prec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "full_norm = False\n",
    "# ------------------------------\n",
    "# Setup: create a dummy distance matrix.\n",
    "# ------------------------------\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "# Note: GPdists expects the distance tensor to be tf.float64 (for Cholesky) so we set that,\n",
    "# but the parameter vector itself is in tf.float32.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# Instantiate GPdists: fixed and unfixed versions.\n",
    "# ------------------------------\n",
    "# Fixed instance: precomputes covariance matrix, Cholesky, and precision.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=True,  # Option for full normalization in precision-based log_prob.\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,  # ensure Cholesky and covariance are computed in float64\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',  # choose 'precision' for testing the new option.\n",
    ")\n",
    "\n",
    "# Unfixed instance: recomputes covariance every time.\n",
    "gp_unfixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=False,\n",
    "    full_norm=True,  # will be passed to unfixed precision method\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create a random parameter vector (matches number of vertices).\n",
    "# ------------------------------\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper function to time method calls.\n",
    "# ------------------------------\n",
    "def time_method(method, instance, param, iterations=100, **kwargs):\n",
    "    # Warm-up one call outside timing\n",
    "    _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    start = time.time()\n",
    "    for _ in range(iterations):\n",
    "        _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    return (time.time() - start) / iterations\n",
    "\n",
    "# ------------------------------\n",
    "# Devices to test (CPU and GPU if available)\n",
    "# ------------------------------\n",
    "devices = ['/cpu:0']\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    devices.append('/gpu:0')\n",
    "\n",
    "# ------------------------------\n",
    "# Run tests on each device.\n",
    "# ------------------------------\n",
    "for device in devices:\n",
    "    print(\"\\nTesting on device:\", device)\n",
    "    with tf.device(device):\n",
    "        # Fixed methods.\n",
    "        t_fixed_tf = time_method(gp_fixed._return_log_prob_fixed_tf, gp_fixed, parameter)\n",
    "        t_fixed_prec = time_method(gp_fixed._return_log_prob_fixed_prec, gp_fixed, parameter, full_norm=True)\n",
    "        \n",
    "        # Unfixed methods.\n",
    "        t_unfixed_tf = time_method(gp_unfixed._return_log_prob_unfixed_tf, gp_unfixed, parameter)\n",
    "        t_unfixed_prec = time_method(gp_unfixed._return_log_prob_unfixed_prec, gp_unfixed, parameter, full_norm=True)\n",
    "        \n",
    "        # Compute log probabilities (for a single call).\n",
    "        lp_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "        lp_unfixed_tf = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_prec = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "        \n",
    "        print(\"Log probability (Fixed TF):        \", lp_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Prec):        \", lp_fixed_prec.numpy())\n",
    "        print(\"Log probability (Unfixed TF):        \", lp_unfixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Prec):      \", lp_unfixed_prec.numpy())\n",
    "        \n",
    "        print(\"\\nAverage runtime per call:\")\n",
    "        print(\"  Fixed TF method:      {:.6f} sec\".format(t_fixed_tf))\n",
    "        print(\"  Fixed Precision method: {:.6f} sec\".format(t_fixed_prec))\n",
    "        print(\"  Unfixed TF method:    {:.6f} sec\".format(t_unfixed_tf))\n",
    "        print(\"  Unfixed Precision method: {:.6f} sec\".format(t_unfixed_prec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0416b44",
   "metadata": {},
   "source": [
    "# bloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922ebd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Generate a random positive definite covariance matrix for a 5-dimensional Gaussian.\n",
    "n = 5\n",
    "# Create a random matrix and form a covariance matrix by A * A^T.\n",
    "A = tf.random.normal((n, n), dtype=tf.float64)\n",
    "cov = tf.matmul(A, A, transpose_b=True) + tf.eye(n, dtype=tf.float64)*1e-3\n",
    "mean = tf.random.normal((n,), dtype=tf.float64)\n",
    "x = tf.random.normal((n,), dtype=tf.float64)\n",
    "\n",
    "# 1. Log probability using TFP's MultivariateNormalFullCovariance:\n",
    "dist = tfd.MultivariateNormalFullCovariance(loc=mean, covariance_matrix=cov)\n",
    "log_prob_tfp = dist.log_prob(x)\n",
    "\n",
    "# 2. Log probability using the full Gaussian formula:\n",
    "#    log p(x) = -0.5 * [ n*log(2) + log|cov| + (x-mean)^T cov^-1 (x-mean) ]\n",
    "def full_gaussian_log_prob(x, mean, cov):\n",
    "    n = tf.cast(tf.shape(x)[0], cov.dtype)\n",
    "    diff = x - mean\n",
    "    inv_cov = tf.linalg.inv(cov)\n",
    "    log_det_cov = tf.linalg.logdet(cov)\n",
    "    quad_form = tf.tensordot(diff, tf.linalg.matvec(inv_cov, diff), axes=1)\n",
    "    # Cast constant 2*pi to the same dtype as cov\n",
    "    two_pi = tf.constant(2 * math.pi, dtype=cov.dtype)\n",
    "    return -0.5 * (n * tf.math.log(two_pi) + log_det_cov + quad_form)\n",
    "\n",
    "log_prob_full = full_gaussian_log_prob(x, mean, cov)\n",
    "\n",
    "# 3. Log probability using the precision matrix directly:\n",
    "#    We use the fact that:\n",
    "#      log p(x) = 0.5 * log|Q| - 0.5 * (x-mean)^T Q (x-mean) - (n/2)*log(2)\n",
    "#    where Q = cov^-1.\n",
    "Q = tf.linalg.inv(cov)\n",
    "log_det_Q = tf.linalg.logdet(Q)\n",
    "diff = x - mean\n",
    "quad_form_precision = tf.tensordot(diff, tf.linalg.matvec(Q, diff), axes=1)\n",
    "two_pi = tf.constant(2 * math.pi, dtype=cov.dtype)\n",
    "log_prob_precision = 0.5 * log_det_Q - 0.5 * quad_form_precision - 0.5 * tf.cast(n, cov.dtype) * tf.math.log(two_pi)\n",
    "\n",
    "print(\"Log probability (TFP):         \", log_prob_tfp.numpy())\n",
    "print(\"Log probability (Full formula):\", log_prob_full.numpy())\n",
    "print(\"Log probability (Precision):   \", log_prob_precision.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2b92bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920d2663",
   "metadata": {},
   "source": [
    "# SPDE METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8628c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97e8e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using fs dir = /data1/projects/dumoulinlab/Lab_members/Marcus/projects/csf/derivatives/freesurfer\n",
      "Adding offset to mesh...\n",
      "Adding offset to mesh...\n",
      "Adding offset to mesh...\n",
      "Adding offset to mesh...\n",
      "Adding offset to mesh...\n",
      "Adding offset to mesh...\n",
      "centering!\n",
      "Faces with missing vx: 319983\n",
      "Faces with long edges: 1555\n",
      "0.0234893798828125\n",
      "centering!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/projects/dumoulinlab/Lab_members/Marcus/programs/dpu_mini/dpu_mini/mesh_format.py:400: RuntimeWarning: Mean of empty slice.\n",
      "  centre_lat = lat[centre_bool].mean()\n",
      "/home/daghlian/.conda/envs/bcoder005/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/data1/projects/dumoulinlab/Lab_members/Marcus/programs/dpu_mini/dpu_mini/mesh_format.py:401: RuntimeWarning: Mean of empty slice.\n",
      "  centre_lon = lon[centre_bool].mean()\n",
      "/data1/projects/dumoulinlab/Lab_members/Marcus/programs/dpu_mini/dpu_mini/mesh_maker.py:527: RuntimeWarning: Mean of empty slice.\n",
      "  flat[connected_pts] -= flat[connected_pts].mean(axis=0)\n",
      "/home/daghlian/.conda/envs/bcoder005/lib/python3.11/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/data1/projects/dumoulinlab/Lab_members/Marcus/programs/dpu_mini/dpu_mini/mesh_maker.py:528: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  scale_x = (infl_x.max() - infl_x.min()) / (flat[:,0].max() - flat[:,0].min())\n",
      "/data1/projects/dumoulinlab/Lab_members/Marcus/programs/dpu_mini/dpu_mini/mesh_maker.py:529: RuntimeWarning: invalid value encountered in multiply\n",
      "  flat *= scale_x*3 # Meh seems nice enough\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces with missing vx: 327680\n",
      "Faces with long edges: 0\n",
      "0.0\n",
      "Missing 2 vx\n",
      "If you want to be more inclusive try again with morph>0\n",
      "Missing 2 vx\n",
      "If you want to be more inclusive try again with morph>0\n",
      "3405\n",
      "Creating distance by distance matrices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating geodesic distances:   0%|          | 0/3405 [00:00<?, ?it/s]/home/daghlian/.conda/envs/bcoder005/lib/python3.11/site-packages/scipy/sparse/linalg/_dsolve/linsolve.py:597: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  return splu(A).solve\n",
      "Calculating geodesic distances: 100%|| 3405/3405 [00:08<00:00, 378.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sub = 'fsaverage'\n",
    "from ncsf_bayesian.ncsf_load_saved_info import *\n",
    "from dpu_mini.mesh_maker import *\n",
    "gm = GenMeshMaker(sub=sub, fs_dir=ncsf_fsdir)\n",
    "mask = dag_load_roi(sub, fs_dir=ncsf_fsdir, roi='lh.V1_ex')\n",
    "mask_lh = mask[:gm.n_vx['lh']]\n",
    "gm.make_flat_map(\n",
    "    mask, morph=2,    \n",
    ")\n",
    "sm = dag_submesh_from_mesh(mesh_info=gm.mesh_info['pial']['lh'], submesh_bool=mask_lh)\n",
    "gdists = dag_pairwise_geodesic_distance(\n",
    "    gm.mesh_info['pial']['lh'], mask_lh, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7fdbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as splinalg\n",
    "from braincoder.bprf_mcmc import mds_embedding, compute_euclidean_distance_matrix\n",
    "# --- Utility Functions for Embedding & Distance Matrix ---\n",
    "# --- Base Class: Common Data & Functions ---\n",
    "\n",
    "class GPBase:\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Base class for GPdists that sets up the distance matrix and common parameters.\n",
    "        \n",
    "        Args:\n",
    "            dists (array-like): Distance matrix.\n",
    "            **kwargs: Keyword arguments that include:\n",
    "                - psd_control: Either 'euclidean' (will embed to Euclidean space) or 'none'.\n",
    "                - embedding_dim: Dimensionality for MDS embedding.\n",
    "                - dists_dtype: TensorFlow dtype (default: tf.float64).\n",
    "        \"\"\"\n",
    "        self.kernel = kwargs.get('kernel', 'RBF')\n",
    "        self.inducer_selection = kwargs.get('inducer_selection', 'random')\n",
    "\n",
    "        # Fixed GP hyperparameters (when fixed_params is True)\n",
    "        self.fixed_params = kwargs.get('fixed_params', 'unfixed') # fixed_vl, fixed_all\n",
    "        self.f_gp_variance = kwargs.get('gp_variance', None)\n",
    "        self.f_gp_lengthscale = kwargs.get('gp_lengthscale', None)\n",
    "        self.f_gp_mean = kwargs.get('gp_mean', 0.0)\n",
    "        self.f_gp_nugget = kwargs.get('gp_nugget', 0.0)\n",
    "\n",
    "\n",
    "# --- Dense (Standard) GP Class ---\n",
    "\n",
    "class GPdistsDense(GPBase):\n",
    "    def __init__(self, dists, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the GPdists class.\n",
    "        Objective: take geodesic distances (dists) per vertex on the cortex\n",
    "        Use this to construct a covariance matrix \n",
    "        which we can use as a prior for smoothness during encoding model fitting\n",
    "\n",
    "        Args:\n",
    "            dists (array-like): The input distance matrix.\n",
    "            **kwargs: Optional parameters for controlling behavior, such as:\n",
    "                - psd_control: Method for ensuring positive semidefiniteness.\n",
    "                - dists_dtype: Data type for tensor conversion.\n",
    "                - fixed_params: Fixing (some) of the GP parameters? Precomputes what is possible for efficiency\n",
    "                    'unfixed'       Everything can change\n",
    "                    'fixed_vl'      variance, lengthscale are fixed, others can change\n",
    "                    'fixed_all'     Everything is fixed\n",
    "                - gp_variance, gp_lengthscale, gp_mean, gp_nugget: GP hyperparameters.\n",
    "                - kernel: Choice of covariance function (default: 'RBF').\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.kernel = kwargs.get('kernel', 'RBF')\n",
    "        self.inducer_selection = kwargs.get('inducer_selection', 'random')\n",
    "\n",
    "        # Setup distance matrix and positive semidefinite control\n",
    "        self.psd_control   = kwargs.get('psd_control', 'euclidean')  # 'euclidean' or 'none'\n",
    "        self.embedding_dim = kwargs.get('embedding_dim', 10)\n",
    "        self.dists_dtype   = kwargs.get('dists_dtype', tf.float64)\n",
    "        self.dists_raw = tf.convert_to_tensor(dists, dtype=self.dists_dtype)\n",
    "        self.dists_raw = (self.dists_raw + tf.transpose(self.dists_raw)) / 2.0\n",
    "\n",
    "        if self.psd_control == 'euclidean':\n",
    "            print('Embedding in Euclidean space...')\n",
    "            X = mds_embedding(self.dists_raw, self.embedding_dim)\n",
    "            self.dists = compute_euclidean_distance_matrix(X)\n",
    "        else:\n",
    "            self.dists = self.dists_raw\n",
    "\n",
    "        self.n_vx = self.dists.shape[0]\n",
    "\n",
    "        # Precompute covariance related matrices if parameters are fixed\n",
    "        if self.fixed_params == 'unfixed':\n",
    "            # Nothing is fixed...\n",
    "            self.cov_matrix = None\n",
    "            self.prec_matrix = None\n",
    "            self.chol = None\n",
    "            self.gp_prior_dist = None\n",
    "        elif self.fixed_params == 'fixed_all':\n",
    "            print('Precomputing covariance matrix...')\n",
    "            self.cov_matrix = self.return_sigma(\n",
    "                gp_lengthscale=self.f_gp_lengthscale,\n",
    "                gp_variance=self.f_gp_variance,\n",
    "                gp_nugget=self.f_gp_nugget,\n",
    "            )\n",
    "            # Compute precision matrix once\n",
    "            self.prec_matrix = tf.cast(tf.linalg.inv(self.cov_matrix), dtype=tf.float32)\n",
    "            print('Precomputing Cholesky decomposition...')\n",
    "            self.chol = tf.linalg.cholesky(tf.cast(self.cov_matrix, dtype=self.dists_dtype))\n",
    "            # Create the fixed prior distribution\n",
    "            self.gp_prior_dist = tfd.MultivariateNormalTriL(\n",
    "                loc=tf.cast(tf.fill([self.n_vx], self.f_gp_mean), dtype=tf.float32),\n",
    "                scale_tril=tf.cast(self.chol, dtype=tf.float32),\n",
    "                allow_nan_stats=False,\n",
    "            )\n",
    "        elif self.fixed_params == 'fixed_vl':\n",
    "            raise NotImplementedError(\"Fixed parameters with 'fixed_vl' option is not implemented yet.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid fixed_params option: {self.fixed_params}. Choose from 'unfixed', 'fixed_vl', or 'fixed_all'.\")\n",
    "        self.set_log_prob()\n",
    "\n",
    "    @tf.function\n",
    "    def return_sigma(self, gp_lengthscale, gp_variance, gp_nugget=0.0, dists=None):\n",
    "        \"\"\"\n",
    "        Computes the covariance matrix using the chosen kernel.\n",
    "\n",
    "        Args:\n",
    "            gp_lengthscale (float): Lengthscale parameter.\n",
    "            gp_variance (float): Variance parameter.\n",
    "            gp_nugget (float): Nugget (noise) term.\n",
    "\n",
    "        Returns:\n",
    "            tf.Tensor: Covariance matrix.\n",
    "        \"\"\"\n",
    "        if dists is None: \n",
    "            dists = self.dists\n",
    "        gp_nugget = tf.cast(gp_nugget, dtype=self.dists_dtype)\n",
    "        gp_variance = tf.cast(gp_variance, dtype=self.dists_dtype)\n",
    "        gp_lengthscale = tf.cast(gp_lengthscale, dtype=self.dists_dtype)\n",
    "\n",
    "        if self.kernel == 'RBF':\n",
    "            cov_matrix = tf.square(gp_variance) * tf.exp(\n",
    "                -tf.square(dists) / (2.0 * tf.square(gp_lengthscale))\n",
    "            )\n",
    "        elif self.kernel == 'matern52':\n",
    "            sqrt5 = tf.cast(tf.sqrt(5.0), dtype=self.dists_dtype)\n",
    "            frac1 = (sqrt5 * dists) / gp_lengthscale\n",
    "            frac2 = (5.0 * tf.square(dists)) / (3.0 * tf.square(gp_lengthscale))\n",
    "            cov_matrix = tf.square(gp_variance) * (1 + frac1 + frac2) * tf.exp(-frac1)\n",
    "        elif self.kernel == 'laplace':\n",
    "            cov_matrix = tf.square(gp_variance) * tf.exp(-dists / gp_lengthscale)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel: {}\".format(self.kernel))\n",
    "        # Add nugget term for numerical stability\n",
    "        return cov_matrix + tf.eye(cov_matrix.shape[0], dtype=self.dists_dtype) * (1e-6 + gp_nugget)    \n",
    "\n",
    "    def set_log_prob(self):\n",
    "        \"\"\"\n",
    "        Set the log probability method based on whether parameters are fixed and the chosen method.\n",
    "        \"\"\"\n",
    "        if self.fixed_params == 'fixed_all':\n",
    "            # When hyperparameters are fixed, use the precomputed distribution or precision\n",
    "            self.return_log_prob = self._return_log_prob_fixed_tf\n",
    "        elif self.fixed_params == 'unfixed':\n",
    "            self.return_log_prob = self._return_log_prob_unfixed_tf\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid fixed_params option: {self.fixed_params}. Choose from 'unfixed', 'fixed_vl', or 'fixed_all'.\")\n",
    "\n",
    "\n",
    "    @tf.function\n",
    "    def _return_log_prob_fixed_tf(self, parameter, gp_lengthscale, gp_variance, gp_mean=0.0, gp_nugget=0.0, n_inducers=None):\n",
    "        \"\"\"\n",
    "        Fixed parameters using TensorFlow distribution.\n",
    "        The extra hyperparameter inputs are included to maintain the gradient graph,\n",
    "        even though they are not used.\n",
    "        \"\"\"\n",
    "        # Note: The extra terms are added via tf.stop_gradient to keep gradients flowing\n",
    "        extra = tf.stop_gradient(gp_lengthscale + gp_variance + gp_mean + gp_nugget) * 0.0\n",
    "        return self.gp_prior_dist.log_prob(parameter) + extra\n",
    "\n",
    "    @tf.function\n",
    "    def _return_log_prob_unfixed_tf(self, parameter, gp_lengthscale, gp_variance, gp_mean=0.0, gp_nugget=0.0, n_inducers=None):\n",
    "        \"\"\"\n",
    "        Unfixed parameters using TensorFlow distribution.\n",
    "        Recompute covariance and Cholesky decomposition on the fly.\n",
    "        Optionally uses random selection of n_inducers for sparse GP approximation.\n",
    "        \"\"\"\n",
    "        if n_inducers is None or n_inducers >= self.n_vx:\n",
    "            # Full GP\n",
    "            cov_matrix = self.return_sigma(gp_lengthscale, gp_variance, gp_nugget)\n",
    "            chol = tf.linalg.cholesky(tf.cast(cov_matrix, dtype=self.dists_dtype))\n",
    "\n",
    "            gp_prior_dist = tfd.MultivariateNormalTriL(\n",
    "                loc=tf.fill([self.n_vx], tf.squeeze(gp_mean)),\n",
    "                scale_tril=tf.cast(chol, dtype=tf.float32),\n",
    "                allow_nan_stats=False,\n",
    "            )\n",
    "            return gp_prior_dist.log_prob(parameter)\n",
    "        else:\n",
    "            # Sparse GP approximation using inducing points\n",
    "            if n_inducers <= 0:\n",
    "                raise ValueError(\"n_inducers must be a positive integer.\")\n",
    "            inducing_indices, inducing_dists = self._return_inducing_idx_and_dists(n_inducers=n_inducers)\n",
    "            # Get the parameter values at the inducing points\n",
    "            inducing_parameter = tf.gather(parameter, inducing_indices)\n",
    "\n",
    "            # Calculate the covariance matrix for the inducing points\n",
    "            inducing_cov_matrix = self.return_sigma(gp_lengthscale, gp_variance, gp_nugget, dists=inducing_dists)\n",
    "            inducing_chol = tf.linalg.cholesky(tf.cast(inducing_cov_matrix, dtype=self.dists_dtype))\n",
    "\n",
    "            inducing_gp_prior_dist = tfd.MultivariateNormalTriL(\n",
    "                loc=tf.fill([n_inducers], tf.squeeze(gp_mean)),\n",
    "                scale_tril=tf.cast(inducing_chol, dtype=tf.float32),\n",
    "                allow_nan_stats=False,\n",
    "            )\n",
    "            return inducing_gp_prior_dist.log_prob(inducing_parameter)\n",
    "    \n",
    "    @tf.function\n",
    "    def _return_inducing_idx_and_dists(self, n_inducers):\n",
    "        if self.inducer_selection == 'random':\n",
    "            # Randomly select indices for inducing points\n",
    "            inducing_indices = tf.random.shuffle(tf.range(self.n_vx))[:n_inducers]\n",
    "            inducing_indices = tf.sort(inducing_indices)  # Keep them sorted for easier indexing\n",
    "\n",
    "        elif self.inducer_selection == 'close':\n",
    "            centre_idx = np.random.randint(0, self.n_vx)\n",
    "            # Get the indices of the closest n_inducers points\n",
    "            _, inducing_indices = tf.math.top_k(-self.dists[centre_idx, :], k=n_inducers)\n",
    "            inducing_indices = tf.sort(inducing_indices)  # Keep sorted\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown inducer selection method: {self.inducer_selection}\")\n",
    "\n",
    "        # Gather distances for the selected inducing points\n",
    "        inducing_dists = tf.gather(tf.gather(self.dists, inducing_indices, axis=0), inducing_indices, axis=1)\n",
    "        \n",
    "        return inducing_indices, inducing_dists\n",
    "\n",
    "# --- Lindgren SPDE GP Class ---\n",
    "\n",
    "class GPLindgren(GPBase):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        GPdists class using the Lindgren SPDE approach (Matern 5/2).\n",
    "        Requires mesh information to be provided.\n",
    "        \n",
    "        Keyword arguments:\n",
    "            mesh_vertices, mesh_faces: Required for assembling the FEM matrices.\n",
    "            gp_variance, gp_lengthscale, gp_nugget: Hyperparameters.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.kernel = 'matern52_lindgren'\n",
    "        print(\"For GPdistsLindgren, kernel must be 'matern52_lindgren'.\")\n",
    "        self.mesh_vertices = kwargs.get('mesh_vertices', None)\n",
    "        self.n_vx = self.mesh_vertices.shape[0]\n",
    "        self.mesh_faces = kwargs.get('mesh_faces', None)\n",
    "        if self.mesh_vertices is None or self.mesh_faces is None:\n",
    "            raise ValueError(\"Mesh vertices and faces must be provided for Lindgren SPDE method.\")\n",
    "        self.full_norm = kwargs.get('full_norm', False)\n",
    "        self.fixed_params = kwargs.get('fixed_params', 'unfixed')\n",
    "        # If fixed_params is used and all parameters are fixed, you could precompute.\n",
    "        # Here, we leave it to the log probability function for demonstration.\n",
    "        self.build_Q_base()\n",
    "        self.set_log_prob()\n",
    "\n",
    "    def set_log_prob(self):\n",
    "        \"\"\"\n",
    "        Set the log probability method for the Lindgren method.\n",
    "        \"\"\"\n",
    "        self.return_log_prob = self._return_log_prob_lindgren\n",
    "\n",
    "    def build_Q_base(self):\n",
    "        \"\"\"\n",
    "        Build a sparse precision matrix Q using a Lindgren SPDE formulation for Matern 5/2.\n",
    "        In this dummy example, we use the mesh connectivity.\n",
    "        \"\"\"\n",
    "        faces = self.mesh_faces\n",
    "        row_idx = []\n",
    "        col_idx = []\n",
    "        values = []\n",
    "        # Dummy finite element assembly: assign weights per face.\n",
    "        for tri in faces:\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    vi, vj = tri[i], tri[j]\n",
    "                    row_idx.append(vi)\n",
    "                    col_idx.append(vj)\n",
    "                    values.append(2.0 if vi == vj else -1.0)\n",
    "        self.Q_base = sp.coo_matrix((values, (row_idx, col_idx)), shape=(self.n_vx, self.n_vx)).tocsc()\n",
    "\n",
    "    def build_lindgren_precision_matrix(self, gp_lengthscale, gp_variance, gp_nugget):\n",
    "        \"\"\"\n",
    "        Build a sparse precision matrix Q using a Lindgren SPDE formulation for Matern 5/2.\n",
    "        \"\"\"\n",
    "        # Matern 5/2 SPDE: kappa = sqrt(5)/lengthscale.\n",
    "        kappa = np.sqrt(5.0) / gp_lengthscale\n",
    "        scaled_Q = kappa**2 * sp.eye(self.n_vx, format=\"csc\") + self.Q_base\n",
    "        # Approximate precision matrix Q = (scaled_Q)^T @ (scaled_Q).\n",
    "        Q = (scaled_Q.transpose() @ scaled_Q).tocoo()\n",
    "        # Scale by variance and add nugget.\n",
    "        Q = Q / gp_variance + gp_nugget * sp.eye(self.n_vx, format=\"coo\")\n",
    "        return Q\n",
    "\n",
    "    def convert_scipy_sparse_to_tf(self, Q_sparse):\n",
    "        \"\"\"\n",
    "        Convert a SciPy sparse (COO) matrix to a TensorFlow SparseTensor.\n",
    "        \"\"\"\n",
    "        Q_coo = Q_sparse.tocoo()\n",
    "        indices = np.vstack((Q_coo.row, Q_coo.col)).T\n",
    "        return tf.sparse.SparseTensor(\n",
    "            indices=indices,\n",
    "            values=Q_coo.data.astype(np.float32),\n",
    "            dense_shape=Q_coo.shape\n",
    "        )\n",
    "\n",
    "    def _log_prob_lindgren_py(self, parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget):\n",
    "        \"\"\"\n",
    "        Python (NumPy/Scipy) implementation of the log probability via the Lindgren method.\n",
    "        This routine is wrapped via tf.py_function.\n",
    "        \"\"\"\n",
    "        gp_lengthscale = float(gp_lengthscale)\n",
    "        gp_variance = float(gp_variance)\n",
    "        gp_nugget = float(gp_nugget)\n",
    "        gp_mean = float(gp_mean)\n",
    "        parameter = np.array(parameter)\n",
    "        Q_sparse = self.build_lindgren_precision_matrix(gp_lengthscale, gp_variance, gp_nugget)\n",
    "        x = (parameter - gp_mean).reshape(-1, 1)\n",
    "        Q_tf = self.convert_scipy_sparse_to_tf(Q_sparse)\n",
    "        Q_tf = tf.sparse.reorder(Q_tf)\n",
    "        x_tf = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "        xT_Q_x = tf.squeeze(tf.matmul(tf.transpose(x_tf), tf.sparse.sparse_dense_matmul(Q_tf, x_tf))).numpy()\n",
    "        Q_chol = splinalg.splu(Q_sparse)\n",
    "        log_det_Q = np.sum(np.log(np.abs(Q_chol.U.diagonal())))\n",
    "        n = x.shape[0]\n",
    "        log_prob = -0.5 * xT_Q_x + 0.5 * log_det_Q - 0.5 * n * math.log(2 * math.pi)\n",
    "        return np.array(log_prob, dtype=np.float32)\n",
    "\n",
    "    def _return_log_prob_lindgren(self, parameter, gp_lengthscale, gp_variance, gp_mean=0.0, gp_nugget=0.0, n_inducers=None):\n",
    "        \"\"\"\n",
    "        Compute the log probability using the Lindgren SPDE approach.\n",
    "        This function wraps the Python routine via tf.py_function.\n",
    "        \"\"\"\n",
    "        logp = tf.py_function(\n",
    "            func=self._log_prob_lindgren_py,\n",
    "            inp=[parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget],\n",
    "            Tout=tf.float32\n",
    "        )\n",
    "        return logp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99d8d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding in Euclidean space...\n"
     ]
    }
   ],
   "source": [
    "# Compare with GPdists\n",
    "\n",
    "gpd = GPdistsDense(\n",
    "    dists=gdists,\n",
    "    kernel='matern52',\n",
    "    psd_method='none'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46282f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GPdistsLindgren, kernel must be 'matern52_lindgren'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gps = GPLindgren(\n",
    "    mesh_vertices=sm['coords'],\n",
    "    mesh_faces=sm['faces'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89195058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1941488/2444430736.py:316: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  Q_chol = splinalg.splu(Q_sparse)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd541a24850>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = []\n",
    "b = []\n",
    "for i in range(50):\n",
    "    test = np.random.normal(size=(sm['coords'].shape[0],)).astype(np.float32)\n",
    "    a.append(gpd.return_log_prob(\n",
    "        parameter=test,\n",
    "        gp_lengthscale=5.0,\n",
    "        gp_variance=1.0,\n",
    "        gp_mean=0.0,\n",
    "        gp_nugget=0.1,\n",
    "    ))\n",
    "\n",
    "    b.append(gps.return_log_prob(\n",
    "        parameter=test,\n",
    "        gp_lengthscale=0.1,\n",
    "        gp_variance=1.0,\n",
    "        gp_mean=0.0,\n",
    "        gp_nugget=0.1,\n",
    "    ))\n",
    "plt.scatter(\n",
    "    a,b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ffa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q_sparse = build_spde_precision_matrix_matern52(vx, faces, lengthscale, variance, nugget)\n",
    "logp = compute_log_prob(vertex_values, Q_sparse)\n",
    "\n",
    "print(\"Log probability:\", logp.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcoder005",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

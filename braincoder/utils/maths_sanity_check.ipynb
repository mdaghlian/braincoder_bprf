{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a73c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:35:21.712654: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-25 12:35:21.712717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-25 12:35:21.712732: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 12:35:21.722779: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Sanity check on implementation of \n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import time\n",
    "# Set a limit on the memory usage of the GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "                gpu,\n",
    "                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8037956",
   "metadata": {},
   "source": [
    "# Ensure that log prob calculations are the same as tfp implementation & faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d71eb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:35:31.682310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: Tesla K40m, pci bus id: 0000:03:00.0, compute capability: 3.5\n"
     ]
    }
   ],
   "source": [
    "# Define your array (as a TensorFlow tensor)\n",
    "n_rows = 10000 # i.e., number of voxels \n",
    "n_cols = 200 # i.e., number of samples in timeseries\n",
    "num_iterations = 1000\n",
    "data = tf.constant(np.random.rand(n_rows, n_cols), dtype=tf.float32)\n",
    "scale_values = tf.constant(np.random.rand(n_rows, 1), dtype=tf.float32)\n",
    "dof_values = tf.constant(np.random.rand(n_rows, 1), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2112a",
   "metadata": {},
   "source": [
    "#### testing calculate_log_prob_gauss_loc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0464cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with GPU\n",
      "Custom log probability calculation time over 1000 iterations: 1.022761 seconds\n",
      "TFP log probability calculation time over 1000 iterations: 1.914832 seconds\n",
      "Custom method is  1.872 x faster\n",
      "     tfd,        custom\n",
      "    -1.394,     -1.394\n",
      "    -0.469,     -0.469\n",
      "    -0.577,     -0.577\n",
      "    -1.190,     -1.190\n",
      "    -1.094,     -1.094\n",
      "   -19.759,    -19.759\n",
      "     0.118,      0.118\n",
      "     0.127,      0.127\n",
      "     0.120,      0.120\n",
      "Trying with CPU\n",
      "Custom log probability calculation time over 1000 iterations: 2.545232 seconds\n",
      "TFP log probability calculation time over 1000 iterations: 3.609536 seconds\n",
      "Custom method is  1.418 x faster\n",
      "     tfd,        custom\n",
      "    -1.394,     -1.394\n",
      "    -0.469,     -0.469\n",
      "    -0.577,     -0.577\n",
      "    -1.190,     -1.190\n",
      "    -1.094,     -1.094\n",
      "   -19.759,    -19.759\n",
      "     0.118,      0.118\n",
      "     0.127,      0.127\n",
      "     0.120,      0.120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from braincoder.utils.math import calculate_log_prob_gauss_loc0\n",
    "for device in ['GPU', 'CPU']:\n",
    "    print(f'Trying with {device}')\n",
    "    with tf.device(f'/{device}:0'):\n",
    "        # Timing the custom log probability calculation\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            calculate_log_prob_gauss_loc0(data, scale_values)  # Now correctly broadcasted\n",
    "        time_custom = time.time() - start_time\n",
    "        output_custom = calculate_log_prob_gauss_loc0(data, scale_values)\n",
    "        # Timing the TFP log probability calculation\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            normal_dist = tfp.distributions.Normal(loc=0.0, scale=scale_values)  # Correct shape\n",
    "            normal_dist.log_prob(data)  # Correct shape\n",
    "        time_tfd = time.time() - start_time\n",
    "        output_tfd = normal_dist.log_prob(data)\n",
    "        # Print the results\n",
    "        print(f\"Custom log probability calculation time over {num_iterations} iterations: {time_custom:.6f} seconds\")\n",
    "        print(f\"TFP log probability calculation time over {num_iterations} iterations: {time_tfd:.6f} seconds\")\n",
    "        print(f\"Custom method is  {time_tfd/time_custom:.3f} x faster\")\n",
    "        print(f\"     tfd,        custom\")\n",
    "        for i1 in range(3):\n",
    "            for i2 in range(3):\n",
    "                print(f'{output_tfd[i1,i2]:10.3f}, {output_custom[i1,i2]:10.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ae006",
   "metadata": {},
   "source": [
    "#### Testing calculate_log_prob_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e41902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with GPU\n",
      "Custom log probability calculation time over 1000 iterations: 3.203720 seconds\n",
      "TFP log probability calculation time over 1000 iterations: 9.060082 seconds\n",
      "Custom method is  2.828 x faster\n",
      "     tfd,        custom\n",
      "    -1.905,     -1.905\n",
      "    -0.840,     -0.840\n",
      "    -1.064,     -1.064\n",
      "    -1.005,     -1.005\n",
      "    -0.972,     -0.972\n",
      "    -2.781,     -2.781\n",
      "    -0.352,     -0.352\n",
      "    -0.323,     -0.323\n",
      "    -0.347,     -0.347\n",
      "Trying with CPU\n",
      "Custom log probability calculation time over 1000 iterations: 7.788781 seconds\n",
      "TFP log probability calculation time over 1000 iterations: 13.588880 seconds\n",
      "Custom method is  1.745 x faster\n",
      "     tfd,        custom\n",
      "    -1.905,     -1.905\n",
      "    -0.840,     -0.840\n",
      "    -1.064,     -1.064\n",
      "    -1.005,     -1.005\n",
      "    -0.972,     -0.972\n",
      "    -2.781,     -2.781\n",
      "    -0.352,     -0.352\n",
      "    -0.323,     -0.323\n",
      "    -0.347,     -0.347\n"
     ]
    }
   ],
   "source": [
    "from braincoder.utils.math import calculate_log_prob_t\n",
    "for device in ['GPU', 'CPU']:\n",
    "    print(f'Trying with {device}')\n",
    "    with tf.device(f'/{device}:0'):\n",
    "        # Timing the custom log probability calculation\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            calculate_log_prob_t(data, scale_values, dof_values)  # Now correctly broadcasted\n",
    "        time_custom = time.time() - start_time\n",
    "        output_custom = calculate_log_prob_t(data, scale_values, dof_values)\n",
    "\n",
    "        # Timing the TFP log probability calculation\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_iterations):\n",
    "            t_dist = tfp.distributions.StudentT(df=dof_values, loc=0.0, scale=scale_values)  # Correct shape\n",
    "            t_dist.log_prob(data)  # Correct shape\n",
    "        time_tfd = time.time() - start_time\n",
    "        output_tfd = t_dist.log_prob(data)\n",
    "\n",
    "        # Print the results\n",
    "        print(f\"Custom log probability calculation time over {num_iterations} iterations: {time_custom:.6f} seconds\")\n",
    "        print(f\"TFP log probability calculation time over {num_iterations} iterations: {time_tfd:.6f} seconds\")\n",
    "        print(f\"Custom method is  {time_tfd/time_custom:.3f} x faster\")\n",
    "        print(f\"     tfd,        custom\")\n",
    "        for i1 in range(3):\n",
    "            for i2 in range(3):\n",
    "                print(f'{output_tfd[i1,i2]:10.3f}, {output_custom[i1,i2]:10.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c1f71",
   "metadata": {},
   "source": [
    "# Check GP dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding in Euclidean space...\n",
      "Precomputing covariance matrix...\n",
      "Precomputing Cholesky decomposition...\n",
      "Log probability (Fixed TF):        -179.84727\n",
      "Log probability (Fixed Precision):   -179.84727\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "# Create a dummy symmetric distance matrix.\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# Set hyperparameters.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# Instantiate GPdists with fixed hyperparameters.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=True, \n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64, # for cholesky... \n",
    "    kernel='RBF',\n",
    ")\n",
    "\n",
    "# For comparison, get the covariance matrix computed by GPdists.\n",
    "cov_matrix = gp_fixed.cov_matrix\n",
    "\n",
    "# Create a random parameter vector (matching the number of vertices).\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (to compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "# Compute log probability using the fixed TF method.\n",
    "log_prob_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "# Compute log probability using the fixed precision method.\n",
    "log_prob_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "# For comparison, compute the log probability \"from scratch\" using the full Gaussian formula.\n",
    "\n",
    "print(\"Log probability (Fixed TF):       \", log_prob_fixed_tf.numpy())\n",
    "print(\"Log probability (Fixed Precision):  \", log_prob_fixed_prec.numpy())\n",
    "# print(\"Log probability (Full formula):     \", log_prob_full.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a7710d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding in Euclidean space...\n",
      "Precomputing covariance matrix...\n",
      "Precomputing Cholesky decomposition...\n",
      "Embedding in Euclidean space...\n",
      "\n",
      "Testing on device: /cpu:0\n",
      "Log probability (Fixed TF):         -150.07254\n",
      "Log probability (Fixed Prec):         -150.07259\n",
      "Log probability (Unfixed TF):         -150.07254\n",
      "Log probability (Unfixed Prec):       -150.07259\n",
      "\n",
      "Average runtime per call:\n",
      "  Fixed TF method:      0.000928 sec\n",
      "  Fixed Precision method: 0.000895 sec\n",
      "  Unfixed TF method:    0.000986 sec\n",
      "  Unfixed Precision method: 0.001044 sec\n",
      "\n",
      "Testing on device: /gpu:0\n",
      "Log probability (Fixed TF):         -150.07254\n",
      "Log probability (Fixed Prec):         -150.07254\n",
      "Log probability (Unfixed TF):         -150.07254\n",
      "Log probability (Unfixed Prec):       -150.07254\n",
      "\n",
      "Average runtime per call:\n",
      "  Fixed TF method:      0.000993 sec\n",
      "  Fixed Precision method: 0.001089 sec\n",
      "  Unfixed TF method:    0.001324 sec\n",
      "  Unfixed Precision method: 0.001957 sec\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "full_norm = True\n",
    "# ------------------------------\n",
    "# Setup: create a dummy distance matrix.\n",
    "# ------------------------------\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "# Note: GPdists expects the distance tensor to be tf.float64 (for Cholesky) so we set that,\n",
    "# but the parameter vector itself is in tf.float32.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# Instantiate GPdists: fixed and unfixed versions.\n",
    "# ------------------------------\n",
    "# Fixed instance: precomputes covariance matrix, Cholesky, and precision.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=full_norm,  # Option for full normalization in precision-based log_prob.\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,  # ensure Cholesky and covariance are computed in float64\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',  # choose 'precision' for testing the new option.\n",
    ")\n",
    "\n",
    "# Unfixed instance: recomputes covariance every time.\n",
    "gp_unfixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=False,\n",
    "    full_norm=full_norm,  # will be passed to unfixed precision method\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create a random parameter vector (matches number of vertices).\n",
    "# ------------------------------\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper function to time method calls.\n",
    "# ------------------------------\n",
    "def time_method(method, instance, param, iterations=5000, **kwargs):\n",
    "    # Warm-up one call outside timing\n",
    "    _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    start = time.time()\n",
    "    for _ in range(iterations):\n",
    "        _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    return (time.time() - start) / iterations\n",
    "\n",
    "# ------------------------------\n",
    "# Devices to test (CPU and GPU if available)\n",
    "# ------------------------------\n",
    "devices = ['/cpu:0']\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    devices.append('/gpu:0')\n",
    "\n",
    "# ------------------------------\n",
    "# Run tests on each device.\n",
    "# ------------------------------\n",
    "for device in devices:\n",
    "    print(\"\\nTesting on device:\", device)\n",
    "    with tf.device(device):\n",
    "        # Fixed methods.\n",
    "        t_fixed_tf = time_method(gp_fixed._return_log_prob_fixed_tf, gp_fixed, parameter)\n",
    "        t_fixed_prec = time_method(gp_fixed._return_log_prob_fixed_prec, gp_fixed, parameter)\n",
    "        \n",
    "        # Unfixed methods.\n",
    "        t_unfixed_tf = time_method(gp_unfixed._return_log_prob_unfixed_tf, gp_unfixed, parameter)\n",
    "        t_unfixed_prec = time_method(gp_unfixed._return_log_prob_unfixed_prec, gp_unfixed, parameter)\n",
    "        \n",
    "        # Compute log probabilities (for a single call).\n",
    "        lp_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_tf = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_prec = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        \n",
    "        print(\"Log probability (Fixed TF):        \", lp_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Prec):        \", lp_fixed_prec.numpy())\n",
    "        print(\"Log probability (Unfixed TF):        \", lp_unfixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Prec):      \", lp_unfixed_prec.numpy())\n",
    "        \n",
    "        print(\"\\nAverage runtime per call:\")\n",
    "        print(\"  Fixed TF method:      {:.6f} sec\".format(t_fixed_tf))\n",
    "        print(\"  Fixed Precision method: {:.6f} sec\".format(t_fixed_prec))\n",
    "        print(\"  Unfixed TF method:    {:.6f} sec\".format(t_unfixed_tf))\n",
    "        print(\"  Unfixed Precision method: {:.6f} sec\".format(t_unfixed_prec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from braincoder.bprf_mcmc import GPdists, mds_embedding, compute_euclidean_distance_matrix\n",
    "tfd = tfp.distributions\n",
    "full_norm = False\n",
    "# ------------------------------\n",
    "# Setup: create a dummy distance matrix.\n",
    "# ------------------------------\n",
    "n_vx = 50\n",
    "rand = tf.random.uniform((n_vx, n_vx), minval=0, maxval=1, dtype=tf.float64)\n",
    "dists = (rand + tf.transpose(rand)) / 2.0\n",
    "dists = dists - tf.linalg.diag(tf.linalg.diag_part(dists))\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "# Note: GPdists expects the distance tensor to be tf.float64 (for Cholesky) so we set that,\n",
    "# but the parameter vector itself is in tf.float32.\n",
    "gp_variance = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_lengthscale = tf.constant(1.0, dtype=tf.float32)\n",
    "gp_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "gp_nugget = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "# ------------------------------\n",
    "# Instantiate GPdists: fixed and unfixed versions.\n",
    "# ------------------------------\n",
    "# Fixed instance: precomputes covariance matrix, Cholesky, and precision.\n",
    "gp_fixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=True,\n",
    "    full_norm=True,  # Option for full normalization in precision-based log_prob.\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,  # ensure Cholesky and covariance are computed in float64\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',  # choose 'precision' for testing the new option.\n",
    ")\n",
    "\n",
    "# Unfixed instance: recomputes covariance every time.\n",
    "gp_unfixed = GPdists(\n",
    "    dists,\n",
    "    fixed_params=False,\n",
    "    full_norm=True,  # will be passed to unfixed precision method\n",
    "    gp_variance=gp_variance,\n",
    "    gp_lengthscale=gp_lengthscale,\n",
    "    gp_mean=gp_mean,\n",
    "    gp_nugget=gp_nugget,\n",
    "    psd_control='euclidean',\n",
    "    dists_dtype=tf.float64,\n",
    "    kernel='RBF',\n",
    "    log_prob_method='precision',\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create a random parameter vector (matches number of vertices).\n",
    "# ------------------------------\n",
    "parameter = tf.random.normal([n_vx], dtype=tf.float32)\n",
    "\n",
    "# Warm-up (compile tf.function graphs)\n",
    "_ = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "_ = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Helper function to time method calls.\n",
    "# ------------------------------\n",
    "def time_method(method, instance, param, iterations=100, **kwargs):\n",
    "    # Warm-up one call outside timing\n",
    "    _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    start = time.time()\n",
    "    for _ in range(iterations):\n",
    "        _ = method(param, gp_lengthscale, gp_variance, gp_mean, gp_nugget, **kwargs)\n",
    "    return (time.time() - start) / iterations\n",
    "\n",
    "# ------------------------------\n",
    "# Devices to test (CPU and GPU if available)\n",
    "# ------------------------------\n",
    "devices = ['/cpu:0']\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    devices.append('/gpu:0')\n",
    "\n",
    "# ------------------------------\n",
    "# Run tests on each device.\n",
    "# ------------------------------\n",
    "for device in devices:\n",
    "    print(\"\\nTesting on device:\", device)\n",
    "    with tf.device(device):\n",
    "        # Fixed methods.\n",
    "        t_fixed_tf = time_method(gp_fixed._return_log_prob_fixed_tf, gp_fixed, parameter)\n",
    "        t_fixed_prec = time_method(gp_fixed._return_log_prob_fixed_prec, gp_fixed, parameter, full_norm=True)\n",
    "        \n",
    "        # Unfixed methods.\n",
    "        t_unfixed_tf = time_method(gp_unfixed._return_log_prob_unfixed_tf, gp_unfixed, parameter)\n",
    "        t_unfixed_prec = time_method(gp_unfixed._return_log_prob_unfixed_prec, gp_unfixed, parameter, full_norm=True)\n",
    "        \n",
    "        # Compute log probabilities (for a single call).\n",
    "        lp_fixed_tf = gp_fixed._return_log_prob_fixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_fixed_prec = gp_fixed._return_log_prob_fixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "        lp_unfixed_tf = gp_unfixed._return_log_prob_unfixed_tf(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget)\n",
    "        lp_unfixed_prec = gp_unfixed._return_log_prob_unfixed_prec(parameter, gp_lengthscale, gp_variance, gp_mean, gp_nugget, full_norm=True)\n",
    "        \n",
    "        print(\"Log probability (Fixed TF):        \", lp_fixed_tf.numpy())\n",
    "        print(\"Log probability (Fixed Prec):        \", lp_fixed_prec.numpy())\n",
    "        print(\"Log probability (Unfixed TF):        \", lp_unfixed_tf.numpy())\n",
    "        print(\"Log probability (Unfixed Prec):      \", lp_unfixed_prec.numpy())\n",
    "        \n",
    "        print(\"\\nAverage runtime per call:\")\n",
    "        print(\"  Fixed TF method:      {:.6f} sec\".format(t_fixed_tf))\n",
    "        print(\"  Fixed Precision method: {:.6f} sec\".format(t_fixed_prec))\n",
    "        print(\"  Unfixed TF method:    {:.6f} sec\".format(t_unfixed_tf))\n",
    "        print(\"  Unfixed Precision method: {:.6f} sec\".format(t_unfixed_prec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0416b44",
   "metadata": {},
   "source": [
    "# bloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922ebd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:34:37.433877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-25 12:34:37.433948: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-25 12:34:37.433962: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 12:34:37.447875: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-25 12:34:47.452034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10756 MB memory:  -> device: 0, name: Tesla K40m, pci bus id: 0000:03:00.0, compute capability: 3.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daghlian/.conda/envs/bcoder005/lib/python3.11/site-packages/tensorflow_probability/python/distributions/distribution.py:342: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
      "Instructions for updating:\n",
      "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:34:47.943368: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x5596a1f19c90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability (TFP):          -6.446665187826045\n",
      "Log probability (Full formula): -6.446665187826044\n",
      "Log probability (Precision):    -6.446665187826045\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# Generate a random positive definite covariance matrix for a 5-dimensional Gaussian.\n",
    "n = 5\n",
    "# Create a random matrix and form a covariance matrix by A * A^T.\n",
    "A = tf.random.normal((n, n), dtype=tf.float64)\n",
    "cov = tf.matmul(A, A, transpose_b=True) + tf.eye(n, dtype=tf.float64)*1e-3\n",
    "mean = tf.random.normal((n,), dtype=tf.float64)\n",
    "x = tf.random.normal((n,), dtype=tf.float64)\n",
    "\n",
    "# 1. Log probability using TFP's MultivariateNormalFullCovariance:\n",
    "dist = tfd.MultivariateNormalFullCovariance(loc=mean, covariance_matrix=cov)\n",
    "log_prob_tfp = dist.log_prob(x)\n",
    "\n",
    "# 2. Log probability using the full Gaussian formula:\n",
    "#    log p(x) = -0.5 * [ n*log(2π) + log|cov| + (x-mean)^T cov^-1 (x-mean) ]\n",
    "def full_gaussian_log_prob(x, mean, cov):\n",
    "    n = tf.cast(tf.shape(x)[0], cov.dtype)\n",
    "    diff = x - mean\n",
    "    inv_cov = tf.linalg.inv(cov)\n",
    "    log_det_cov = tf.linalg.logdet(cov)\n",
    "    quad_form = tf.tensordot(diff, tf.linalg.matvec(inv_cov, diff), axes=1)\n",
    "    # Cast constant 2*pi to the same dtype as cov\n",
    "    two_pi = tf.constant(2 * math.pi, dtype=cov.dtype)\n",
    "    return -0.5 * (n * tf.math.log(two_pi) + log_det_cov + quad_form)\n",
    "\n",
    "log_prob_full = full_gaussian_log_prob(x, mean, cov)\n",
    "\n",
    "# 3. Log probability using the precision matrix directly:\n",
    "#    We use the fact that:\n",
    "#      log p(x) = 0.5 * log|Q| - 0.5 * (x-mean)^T Q (x-mean) - (n/2)*log(2π)\n",
    "#    where Q = cov^-1.\n",
    "Q = tf.linalg.inv(cov)\n",
    "log_det_Q = tf.linalg.logdet(Q)\n",
    "diff = x - mean\n",
    "quad_form_precision = tf.tensordot(diff, tf.linalg.matvec(Q, diff), axes=1)\n",
    "two_pi = tf.constant(2 * math.pi, dtype=cov.dtype)\n",
    "log_prob_precision = 0.5 * log_det_Q - 0.5 * quad_form_precision - 0.5 * tf.cast(n, cov.dtype) * tf.math.log(two_pi)\n",
    "\n",
    "print(\"Log probability (TFP):         \", log_prob_tfp.numpy())\n",
    "print(\"Log probability (Full formula):\", log_prob_full.numpy())\n",
    "print(\"Log probability (Precision):   \", log_prob_precision.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcoder005",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
